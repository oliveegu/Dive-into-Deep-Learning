{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备知识\n",
    "\n",
    "### 环境配置\n",
    "  配置清华PyPI镜像（如无法运行，将pip版本升级到>=10.0.0）\n",
    "  pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "### pytorch的数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.9468e+01, 4.5625e-41, 7.9468e+01],\n",
       "        [4.5625e-41, 2.1200e-04, 4.5625e-41],\n",
       "        [2.1200e-04, 4.5625e-41, 2.1055e-04],\n",
       "        [4.5625e-41, 2.1200e-04, 4.5625e-41],\n",
       "        [2.1054e-04, 4.5625e-41, 2.1076e-04]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 7, 6, 3, 5, 4, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "x\n",
    "import numpy as np\n",
    "idx = np.arange(0, 10)\n",
    "idx\n",
    "torch.randperm(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5021,  0.3700, -1.2434],\n",
       "        [-1.2641,  0.3341, -0.1380],\n",
       "        [ 1.2290, -1.1187, -0.5861],\n",
       "        [-0.6914, -0.1367, -1.8566],\n",
       "        [ 0.2754,  0.8988, -0.7595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6793, -0.0930,  0.2309],\n",
       "        [ 0.1451,  0.8055, -0.6148],\n",
       "        [-0.1142, -0.1126,  1.2458],\n",
       "        [-1.8728,  0.2861,  0.6433],\n",
       "        [ 1.6910,  0.8067, -0.9974]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.5021,  0.3700, -1.2434])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5021,  1.3700, -0.2434],\n",
       "        [-1.2641,  0.3341, -0.1380],\n",
       "        [ 1.2290, -1.1187, -0.5861],\n",
       "        [-0.6914, -0.1367, -1.8566],\n",
       "        [ 0.2754,  0.8988, -0.7595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5021,  1.3700, -0.2434, -1.2641,  0.3341],\n",
       "        [-0.1380,  1.2290, -1.1187, -0.5861, -0.6914],\n",
       "        [-0.1367, -1.8566,  0.2754,  0.8988, -0.7595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5021,  1.3700, -0.2434],\n",
       "        [-1.2641,  0.3341, -0.1380],\n",
       "        [ 1.2290, -1.1187, -0.5861],\n",
       "        [-0.6914, -0.1367, -1.8566],\n",
       "        [ 0.2754,  0.8988, -0.7595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5021,  1.3700, -0.2434, -1.2641,  0.3341],\n",
       "        [-0.1380,  1.2290, -1.1187, -0.5861, -0.6914],\n",
       "        [-0.1367, -1.8566,  0.2754,  0.8988, -0.7595]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4979,  2.3700,  0.7566, -0.2641,  1.3341],\n",
       "        [ 0.8620,  2.2290, -0.1187,  0.4139,  0.3086],\n",
       "        [ 0.8633, -0.8566,  1.2754,  1.8988,  0.2405]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4979,  2.3700,  0.7566, -0.2641,  1.3341],\n",
       "        [ 0.8620,  2.2290, -0.1187,  0.4139,  0.3086],\n",
       "        [ 0.8633, -0.8566,  1.2754,  1.8988,  0.2405]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4979,  2.3700,  0.7566],\n",
       "        [-0.2641,  1.3341,  0.8620],\n",
       "        [ 2.2290, -0.1187,  0.4139],\n",
       "        [ 0.3086,  0.8633, -0.8566],\n",
       "        [ 1.2754,  1.8988,  0.2405]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4979, 3.3700, 1.7566],\n",
       "        [0.7359, 2.3341, 1.8620],\n",
       "        [3.2290, 0.8813, 1.4139],\n",
       "        [1.3086, 1.8633, 0.1434],\n",
       "        [2.2754, 2.8988, 1.2405]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4979, 3.3700, 1.7566, 0.7359, 2.3341, 1.8620, 3.2290, 0.8813, 1.4139,\n",
       "        1.3086, 1.8633, 0.1434, 2.2754, 2.8988, 1.2405])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "y = torch.randn(5,3)\n",
    "x\n",
    "y\n",
    "z = x[0, :]\n",
    "z \n",
    "z += 1.\n",
    "x\n",
    "a =  x.view(3,5)\n",
    "a\n",
    "x\n",
    "a\n",
    "x += 1.\n",
    "a\n",
    "b = x.reshape(3, 5)\n",
    "b\n",
    "x\n",
    "b += 1.\n",
    "x\n",
    "c = x.clone().view(15)\n",
    "c.dim()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(1., dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "x\n",
    "x.dim()\n",
    "x.shape\n",
    "x.item()\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.full((3, 3), 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(x).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [0., 3., 3.],\n",
       "        [0., 0., 3.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function triu:\n",
      "\n",
      "triu(...)\n",
      "    triu(input, diagonal=0, out=None) -> Tensor\n",
      "    \n",
      "    Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices\n",
      "    :attr:`input`, the other elements of the result tensor :attr:`out` are set to 0.\n",
      "    \n",
      "    The upper triangular part of the matrix is defined as the elements on and\n",
      "    above the diagonal.\n",
      "    \n",
      "    The argument :attr:`diagonal` controls which diagonal to consider. If\n",
      "    :attr:`diagonal` = 0, all elements on and below the main diagonal are\n",
      "    retained. A positive value excludes just as many diagonals above the main\n",
      "    diagonal, and similarly a negative value includes just as many diagonals below\n",
      "    the main diagonal. The main diagonal are the set of indices\n",
      "    :math:`\\lbrace (i, i) \\rbrace` for :math:`i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]` where\n",
      "    :math:`d_{1}, d_{2}` are the dimensions of the matrix.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        diagonal (int, optional): the diagonal to consider\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(3, 3)\n",
      "        >>> a\n",
      "        tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                [ 0.2072, -1.0680,  0.6602],\n",
      "                [ 0.3480, -0.5211, -0.4573]])\n",
      "        >>> torch.triu(a)\n",
      "        tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                [ 0.0000, -1.0680,  0.6602],\n",
      "                [ 0.0000,  0.0000, -0.4573]])\n",
      "        >>> torch.triu(a, diagonal=1)\n",
      "        tensor([[ 0.0000,  0.5207,  2.0049],\n",
      "                [ 0.0000,  0.0000,  0.6602],\n",
      "                [ 0.0000,  0.0000,  0.0000]])\n",
      "        >>> torch.triu(a, diagonal=-1)\n",
      "        tensor([[ 0.2309,  0.5207,  2.0049],\n",
      "                [ 0.2072, -1.0680,  0.6602],\n",
      "                [ 0.0000, -0.5211, -0.4573]])\n",
      "    \n",
      "        >>> b = torch.randn(4, 6)\n",
      "        >>> b\n",
      "        tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n",
      "                [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])\n",
      "        >>> torch.triu(b, diagonal=1)\n",
      "        tensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],\n",
      "                [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])\n",
      "        >>> torch.triu(b, diagonal=-1)\n",
      "        tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n",
      "                [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n",
      "                [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n",
      "                [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.triu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 3.],\n",
       "        [0., 0., 3.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(x, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [3., 0., 0.],\n",
       "        [3., 3., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(x, diagonal=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function bmm:\n",
      "\n",
      "bmm(...)\n",
      "    bmm(input, mat2, out=None) -> Tensor\n",
      "    \n",
      "    Performs a batch matrix-matrix product of matrices stored in :attr:`input`\n",
      "    and :attr:`mat2`.\n",
      "    \n",
      "    :attr:`input` and :attr:`mat2` must be 3-D tensors each containing\n",
      "    the same number of matrices.\n",
      "    \n",
      "    If :attr:`input` is a :math:`(b \\times n \\times m)` tensor, :attr:`mat2` is a\n",
      "    :math:`(b \\times m \\times p)` tensor, :attr:`out` will be a\n",
      "    :math:`(b \\times n \\times p)` tensor.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out}_i = \\text{input}_i \\mathbin{@} \\text{mat2}_i\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "              For broadcasting matrix products, see :func:`torch.matmul`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the first batch of matrices to be multiplied\n",
      "        mat2 (Tensor): the second batch of matrices to be multiplied\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> input = torch.randn(10, 3, 4)\n",
      "        >>> mat2 = torch.randn(10, 4, 5)\n",
      "        >>> res = torch.bmm(input, mat2)\n",
      "        >>> res.size()\n",
      "        torch.Size([10, 3, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.bmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 45, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(128, 45, 56)\n",
    "y = torch.rand(128, 56, 10)\n",
    "# x bmm y => (128, 45, 10)\n",
    "torch.bmm(x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randint:\n",
      "\n",
      "randint(...)\n",
      "    randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a tensor filled with random integers generated uniformly\n",
      "    between :attr:`low` (inclusive) and :attr:`high` (exclusive).\n",
      "    \n",
      "    The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "    \n",
      "    .. note:\n",
      "        With the global dtype default (``torch.float32``), this function returns\n",
      "        a tensor with dtype ``torch.int64``.\n",
      "    \n",
      "    Args:\n",
      "        low (int, optional): Lowest integer to be drawn from the distribution. Default: 0.\n",
      "        high (int): One above the highest integer to be drawn from the distribution.\n",
      "        size (tuple): a tuple defining the shape of the output tensor.\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.randint(3, 5, (3,))\n",
      "        tensor([4, 3, 4])\n",
      "    \n",
      "    \n",
      "        >>> torch.randint(10, (2, 2))\n",
      "        tensor([[0, 2],\n",
      "                [5, 5]])\n",
      "    \n",
      "    \n",
      "        >>> torch.randint(3, 10, (2, 2))\n",
      "        tensor([[4, 5],\n",
      "                [6, 7]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.randint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 42, 81, 75],\n",
       "        [84, 55, 42, 62],\n",
       "        [91, 89, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 84, 91],\n",
       "        [42, 55, 89],\n",
       "        [81, 42, 62],\n",
       "        [75, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 42, 81, 75],\n",
       "        [84, 55, 42, 62],\n",
       "        [91, 89, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 84, 91],\n",
       "        [42, 55, 89],\n",
       "        [81, 42, 62],\n",
       "        [75, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 42, 81, 75],\n",
       "        [84, 55, 42, 62],\n",
       "        [91, 89, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 84, 91],\n",
       "        [42, 55, 89],\n",
       "        [81, 42, 62],\n",
       "        [75, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[21, 84, 91],\n",
       "        [42, 55, 89],\n",
       "        [81, 42, 62],\n",
       "        [75, 62, 49]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 100, (3, 4))\n",
    "x\n",
    "torch.t(x)\n",
    "x\n",
    "x.t()\n",
    "x\n",
    "x.t_()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., -0.],\n",
       "        [0., 1., 0., 0., -0.],\n",
       "        [0., 0., 1., 0., -0.],\n",
       "        [0., 0., 0., 1., -0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(5)\n",
    "x\n",
    "torch.inverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0977, -1.3256, -0.9236,  1.2527, -2.1494],\n",
       "        [ 0.6247,  0.6490,  0.4926, -1.0789,  0.9728],\n",
       "        [-0.5222, -1.6344,  1.8162, -1.6200, -0.3420],\n",
       "        [-0.9933,  0.9850, -1.7034, -1.5324,  0.3889],\n",
       "        [-0.0337, -0.7669,  1.8041, -0.7126, -0.9463]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3580,  0.7262, -0.0311, -0.1343, -0.1106],\n",
       "        [-0.1700,  0.0627, -0.7001,  0.1930,  0.7829],\n",
       "        [-0.2137, -0.0315, -0.1556, -0.1889,  0.4317],\n",
       "        [-0.1473, -0.3611, -0.1578, -0.3034, -0.1043],\n",
       "        [-0.1716,  0.1353,  0.3908, -0.2833, -0.7856]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(5, 5)\n",
    "y\n",
    "torch.inverse(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3966, -0.3416, -0.4643],\n",
       "        [-1.4352, -0.2513,  0.0960],\n",
       "        [ 0.0291,  0.3043,  0.8332],\n",
       "        [ 0.2177, -0.9424, -2.6561]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "A must be batches of square matrices, but they are 3 by 4 matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a177ee3aeb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: A must be batches of square matrices, but they are 3 by 4 matrices"
     ]
    }
   ],
   "source": [
    "z = torch.randn(4,3)\n",
    "z\n",
    "torch.inverse(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, got 2D, 2D tensors at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:774",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2f1f5a58d7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, got 2D, 2D tensors at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:774"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "z = torch.dot(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function dot:\n",
      "\n",
      "dot(...)\n",
      "    dot(input, tensor) -> Tensor\n",
      "    \n",
      "    Computes the dot product (inner product) of two tensors.\n",
      "    \n",
      "    .. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\n",
      "        tensor(7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3, 4])\n",
    "y = torch.tensor([3, 4])\n",
    "z = torch.dot(x, y)\n",
    "z.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2803,  0.8744,  1.2867,  0.7778],\n",
       "        [ 0.0542, -2.3756,  0.3147, -0.8595],\n",
       "        [-5.1516, -0.6219,  1.0926,  0.9453]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "z = torch.cross(x, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function cross:\n",
      "\n",
      "cross(...)\n",
      "    cross(input, other, dim=-1, out=None) -> Tensor\n",
      "    \n",
      "    \n",
      "    Returns the cross product of vectors in dimension :attr:`dim` of :attr:`input`\n",
      "    and :attr:`other`.\n",
      "    \n",
      "    :attr:`input` and :attr:`other` must have the same size, and the size of their\n",
      "    :attr:`dim` dimension should be 3.\n",
      "    \n",
      "    If :attr:`dim` is not given, it defaults to the first dimension found with the\n",
      "    size 3.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        other (Tensor): the second input tensor\n",
      "        dim  (int, optional): the dimension to take the cross-product in.\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4, 3)\n",
      "        >>> a\n",
      "        tensor([[-0.3956,  1.1455,  1.6895],\n",
      "                [-0.5849,  1.3672,  0.3599],\n",
      "                [-1.1626,  0.7180, -0.0521],\n",
      "                [-0.1339,  0.9902, -2.0225]])\n",
      "        >>> b = torch.randn(4, 3)\n",
      "        >>> b\n",
      "        tensor([[-0.0257, -1.4725, -1.2251],\n",
      "                [-1.1479, -0.7005, -1.9757],\n",
      "                [-1.3904,  0.3726, -1.1836],\n",
      "                [-0.9688, -0.7153,  0.2159]])\n",
      "        >>> torch.cross(a, b, dim=1)\n",
      "        tensor([[ 1.0844, -0.5281,  0.6120],\n",
      "                [-2.4490, -1.5687,  1.9792],\n",
      "                [-0.8304, -1.3037,  0.5650],\n",
      "                [-1.2329,  1.9883,  1.0551]])\n",
      "        >>> torch.cross(a, b)\n",
      "        tensor([[ 1.0844, -0.5281,  0.6120],\n",
      "                [-2.4490, -1.5687,  1.9792],\n",
      "                [-0.8304, -1.3037,  0.5650],\n",
      "                [-1.2329,  1.9883,  1.0551]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function svd:\n",
      "\n",
      "svd(...)\n",
      "    svd(input, some=True, compute_uv=True, out=None) -> (Tensor, Tensor, Tensor)\n",
      "    \n",
      "    This function returns a namedtuple ``(U, S, V)`` which is the singular value\n",
      "    decomposition of a input real matrix or batches of real matrices :attr:`input` such that\n",
      "    :math:`input = U \\times diag(S) \\times V^T`.\n",
      "    \n",
      "    If :attr:`some` is ``True`` (default), the method returns the reduced singular value decomposition\n",
      "    i.e., if the last two dimensions of :attr:`input` are ``m`` and ``n``, then the returned\n",
      "    `U` and `V` matrices will contain only :math:`min(n, m)` orthonormal columns.\n",
      "    \n",
      "    If :attr:`compute_uv` is ``False``, the returned `U` and `V` matrices will be zero matrices\n",
      "    of shape :math:`(m \\times m)` and :math:`(n \\times n)` respectively. :attr:`some` will be ignored here.\n",
      "    \n",
      "    .. note:: The implementation of SVD on CPU uses the LAPACK routine `?gesdd` (a divide-and-conquer\n",
      "              algorithm) instead of `?gesvd` for speed. Analogously, the SVD on GPU uses the MAGMA routine\n",
      "              `gesdd` as well.\n",
      "    \n",
      "    .. note:: Irrespective of the original strides, the returned matrix `U`\n",
      "              will be transposed, i.e. with strides :code:`U.contiguous().transpose(-2, -1).stride()`\n",
      "    \n",
      "    .. note:: Extra care needs to be taken when backward through `U` and `V`\n",
      "              outputs. Such operation is really only stable when :attr:`input` is\n",
      "              full rank with all distinct singular values. Otherwise, ``NaN`` can\n",
      "              appear as the gradients are not properly defined. Also, notice that\n",
      "              double backward will usually do an additional backward through `U` and\n",
      "              `V` even if the original backward is only on `S`.\n",
      "    \n",
      "    .. note:: When :attr:`some` = ``False``, the gradients on :code:`U[..., :, min(m, n):]`\n",
      "              and :code:`V[..., :, min(m, n):]` will be ignored in backward as those vectors\n",
      "              can be arbitrary bases of the subspaces.\n",
      "    \n",
      "    .. note:: When :attr:`compute_uv` = ``False``, backward cannot be performed since `U` and `V`\n",
      "              from the forward pass is required for the backward operation.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor of size :math:`(*, m, n)` where `*` is zero or more\n",
      "                        batch dimensions consisting of :math:`m \\times n` matrices.\n",
      "        some (bool, optional): controls the shape of returned `U` and `V`\n",
      "        compute_uv (bool, optional): option whether to compute `U` and `V` or not\n",
      "        out (tuple, optional): the output tuple of tensors\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(5, 3)\n",
      "        >>> a\n",
      "        tensor([[ 0.2364, -0.7752,  0.6372],\n",
      "                [ 1.7201,  0.7394, -0.0504],\n",
      "                [-0.3371, -1.0584,  0.5296],\n",
      "                [ 0.3550, -0.4022,  1.5569],\n",
      "                [ 0.2445, -0.0158,  1.1414]])\n",
      "        >>> u, s, v = torch.svd(a)\n",
      "        >>> u\n",
      "        tensor([[ 0.4027,  0.0287,  0.5434],\n",
      "                [-0.1946,  0.8833,  0.3679],\n",
      "                [ 0.4296, -0.2890,  0.5261],\n",
      "                [ 0.6604,  0.2717, -0.2618],\n",
      "                [ 0.4234,  0.2481, -0.4733]])\n",
      "        >>> s\n",
      "        tensor([2.3289, 2.0315, 0.7806])\n",
      "        >>> v\n",
      "        tensor([[-0.0199,  0.8766,  0.4809],\n",
      "                [-0.5080,  0.4054, -0.7600],\n",
      "                [ 0.8611,  0.2594, -0.4373]])\n",
      "        >>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))\n",
      "        tensor(8.6531e-07)\n",
      "        >>> a_big = torch.randn(7, 5, 3)\n",
      "        >>> u, s, v = torch.svd(a_big)\n",
      "        >>> torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1)))\n",
      "        tensor(2.6503e-06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1, 4).view(3, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 2], [1, 2], [1, 1], [2, 2], [3, 3]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =[[1, 2],\n",
    "   [1, 2],\n",
    "   [1, 2]]\n",
    "y =[[1, 1],\n",
    "   [2, 2],\n",
    "   [3, 3]]\n",
    "x+y #???\n",
    "torch.tensor(x)+torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 运算的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1.\n",
    "y = 2.\n",
    "before_id = id(y)\n",
    "y = x +y\n",
    "id(y) == before_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1.\n",
    "y = 2.\n",
    "before_id = id(y)\n",
    "y += x\n",
    "id(y) == before_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "y = torch.tensor(2.)\n",
    "before_id = id(y)\n",
    "y += x\n",
    "id(y) == before_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1.)\n",
    "y = torch.tensor(2.)\n",
    "before_id = id(y)\n",
    "torch.add(x, y, y)\n",
    "id(y) == before_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor和NumPy相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5,5)\n",
    "b = a.numpy()\n",
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'index',\n",
       " 'type']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<method-wrapper '__str__' of torch.device object at 0x7f2ec12d0f78>\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() >1:\n",
    "        print(\"cuda device number is:\", torch.cuda.device_count())\n",
    "    else:\n",
    "        device = torch.device(\"cuda\")          \n",
    "        device\n",
    "        dir(device)\n",
    "        print(device.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2942, -2.5035,  1.5652,  ..., -1.3593,  0.2733, -0.5239],\n",
       "         [-0.7564, -0.3513, -0.4343,  ...,  0.0948, -0.2034, -1.4703],\n",
       "         [-1.1445,  1.7627, -1.3090,  ...,  0.7534, -1.8149,  1.1744],\n",
       "         ...,\n",
       "         [ 0.0540, -0.2093, -1.1404,  ...,  0.2720,  0.3714,  1.1082],\n",
       "         [ 0.9434,  0.5345, -0.0240,  ...,  0.6751,  0.1406,  0.2292],\n",
       "         [ 0.1712, -0.1768, -0.3959,  ...,  0.9342,  0.6442, -0.9732]],\n",
       "\n",
       "        [[-0.3481, -0.1899,  0.1072,  ...,  0.4036,  0.1830,  2.5561],\n",
       "         [-0.6004,  0.7683,  1.0864,  ...,  1.5991, -0.5551,  1.0962],\n",
       "         [-0.4070, -0.8509,  0.9666,  ...,  0.3480, -0.4143, -0.6525],\n",
       "         ...,\n",
       "         [-0.8973,  0.8725, -0.1977,  ..., -1.3398, -0.9511,  1.0036],\n",
       "         [-0.3268,  0.8981,  0.5927,  ...,  1.2937, -1.4522, -1.3546],\n",
       "         [ 1.1012,  2.0798, -0.0974,  ...,  0.4860,  0.3893,  1.1060]],\n",
       "\n",
       "        [[ 1.6711,  0.5573, -0.9266,  ...,  0.8801,  0.0031, -0.1855],\n",
       "         [-1.2166,  0.0368, -1.3721,  ...,  1.4197, -0.0888,  0.3864],\n",
       "         [ 0.3210,  0.6118,  0.2664,  ...,  1.1666,  0.1502,  0.5879],\n",
       "         ...,\n",
       "         [ 0.6028,  0.6775, -1.4915,  ...,  0.7101, -0.2088,  2.7944],\n",
       "         [ 1.0989,  0.0881,  0.7029,  ...,  0.5677, -0.3204, -0.0790],\n",
       "         [ 1.2360, -1.5327,  0.4296,  ...,  0.6122,  0.5056, -0.0500]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2455, -0.5005,  0.4108,  ...,  0.6245, -0.0514,  0.5957],\n",
       "         [ 1.1371,  0.0121,  1.0383,  ...,  0.7246, -0.0624,  1.2662],\n",
       "         [ 0.0513,  2.1536, -1.5906,  ..., -2.2377, -0.8203, -2.8660],\n",
       "         ...,\n",
       "         [-0.0855, -0.2227, -0.3482,  ...,  1.3968,  0.7453,  1.4541],\n",
       "         [ 0.2229, -0.9553, -0.1356,  ...,  0.9666,  0.2265,  1.1419],\n",
       "         [-1.3113, -1.4755, -0.5125,  ..., -1.0625, -1.1767, -1.2373]],\n",
       "\n",
       "        [[ 0.0059,  0.7406,  0.9736,  ..., -0.0806, -1.3562,  1.0037],\n",
       "         [-0.0112,  1.1438,  0.8374,  ...,  0.2644, -0.1076, -0.0934],\n",
       "         [-0.7432, -0.9134,  0.4050,  ..., -0.2689, -1.1532,  0.8195],\n",
       "         ...,\n",
       "         [ 1.5509,  1.0903,  0.9643,  ..., -0.2949,  1.1916,  0.2621],\n",
       "         [ 1.9614,  0.1795, -0.1747,  ...,  0.5248,  0.9106, -0.4788],\n",
       "         [ 0.6994, -0.5843, -1.0256,  ...,  0.3509,  1.6210, -0.3688]],\n",
       "\n",
       "        [[-1.5401, -0.4967,  1.8217,  ...,  0.6120, -0.1003, -0.4445],\n",
       "         [-0.4283,  1.3829, -0.3122,  ..., -0.6763,  0.9955, -0.5278],\n",
       "         [-1.0658, -0.3924,  0.3598,  ...,  0.8040, -1.0678, -1.2398],\n",
       "         ...,\n",
       "         [ 0.3204,  0.5579, -0.9916,  ...,  0.6034,  0.0928, -0.0216],\n",
       "         [ 1.2063,  0.2228, -1.0684,  ..., -0.5466,  0.2142,  1.3488],\n",
       "         [-0.2078,  1.8487, -0.9370,  ...,  1.2207, -0.3303,  1.3366]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(123, 456, 789)\n",
    "x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 3]], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randint(1, 5, (2, 2))\n",
    "y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_device = torch.device('cpu') \n",
    "y.to(cpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求梯度(导数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(24.), tensor(4.), tensor(1.))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# y = a**2*x + b*x + c\n",
    "# x = 4, a = 3, b=2, c=5\n",
    "\n",
    "# dy/da = 2*a*x = 2*3*4 =24\n",
    "# dy/db = x = 4\n",
    "# dy/dc = 1\n",
    "x = torch.tensor(4.)\n",
    "a = torch.tensor(3., requires_grad=True)\n",
    "b = torch.tensor(2., requires_grad=True)\n",
    "c = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "\n",
    "y = a**2*x + b*x + c\n",
    "\n",
    "a.grad, b.grad, c.grad\n",
    "\n",
    "torch.autograd.grad(y, [a, b, c])\n",
    "# grads[0]\n",
    "# grads[1]\n",
    "# grads[2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 概念\n",
    "Tensor是这个包的核心类，如果将其属性.requires_grad设置为True，它将开始追踪(track)在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用.backward()来完成所有梯度计算。此Tensor的梯度将累积到.grad属性中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    " y = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y + 5.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
